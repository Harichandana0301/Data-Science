{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueWmxIyWU8fG"
      },
      "source": [
        "# Homework 2\n",
        "\n",
        "**Please type your name and A number here:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "Hspsjhn8yGYM"
      },
      "outputs": [],
      "source": [
        "Name = \"Hari Chandana Kotnani\"\n",
        "assert Name != \"\", 'Please enter your name in the above quotation marks, thanks!'\n",
        "\n",
        "A_number = \"A02395874\"\n",
        "assert A_number != \"\", 'Please enter your A-number in the above quotation marks, thanks!'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUyCA3KvyGYN"
      },
      "source": [
        "In this homework, we will implement a logistic regression from scratch. Your jobs\n",
        "\n",
        "1. Implement the objective function.\n",
        "\n",
        "2. Implement the stochastic gradident descent algorithm to train the logistic regression.\n",
        "\n",
        "3. Implement the mini-batch stochastic gradident descent algorithm to train the logistic regression.\n",
        "\n",
        "4. Submit the .IPYNB file to Canvas.\n",
        "    - Missing the output after execution may hurt your grade.\n",
        "\n",
        "\n",
        "**In this homework, you are not allowed to import other packages, such as PyTorch. You need to write the plain numpy code to implement the algorithms and cannot use sklearn in your implementation.**\n",
        "\n",
        "When computing the gradient and objective function value for GD and mini-batch SGD algorithms, use matrix-vector multiplication rather than a FOR LOOP of vector-vector multiplications.\n",
        "\n",
        "In general, you can expect the following chart regarding the convergence of GD, SGD, and mini-batch SGD.\n",
        "\n",
        "<img src=\"https://docs.google.com/uc?export=download&id=13QpAtDEiaZUbLSPLqzjZTsuCCtbRfnQz\" alt=\"drawing\" width=\"400\"/>\n",
        "\n",
        "**Bonus (15pt)**: add a regularization term to the objective function and train the model based on the new objective function.\n",
        "\n",
        "# 1. Data processing\n",
        "\n",
        "- Download the Diabete dataset from https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary/diabetes\n",
        "- Load the data using sklearn.\n",
        "- Preprocess the data.\n",
        "\n",
        "## 1.1. Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHa_HxmOU8fJ",
        "outputId": "e1e7a08d-c75d-47a0-c6fb-f8e03fb22a60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: (768, 8)\n",
            "Shape of y: (768,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "x_sparse, y = datasets.load_svmlight_file('diabetes.txt')\n",
        "x = x_sparse.toarray()\n",
        "lb = preprocessing.LabelBinarizer()\n",
        "y = lb.fit_transform(y).reshape(-1)\n",
        "print('Shape of x: ' + str(x.shape))\n",
        "print('Shape of y: ' + str(y.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_6NI-WOU8fP"
      },
      "source": [
        "## 1.2. Partition to training and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wY8k5eLOU8fP",
        "outputId": "ba928efa-3a76-46cb-8edd-02489c3b4af8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x_train: (615, 8)\n",
            "Shape of x_test: (153, 8)\n",
            "Shape of y_train: (615,)\n",
            "Shape of y_test: (153,)\n"
          ]
        }
      ],
      "source": [
        "# partition the data to training and test sets\n",
        "n = x.shape[0]\n",
        "n_train = int(np.ceil(n * 0.8))\n",
        "n_test = n - n_train\n",
        "\n",
        "rand_indices = np.random.permutation(n)\n",
        "train_indices = rand_indices[0:n_train]\n",
        "test_indices = rand_indices[n_train:n]\n",
        "\n",
        "x_train = x[train_indices, :]\n",
        "x_test = x[test_indices, :]\n",
        "y_train = y[train_indices]\n",
        "y_test = y[test_indices]\n",
        "\n",
        "print('Shape of x_train: ' + str(x_train.shape))\n",
        "print('Shape of x_test: ' + str(x_test.shape))\n",
        "print('Shape of y_train: ' + str(y_train.shape))\n",
        "print('Shape of y_test: ' + str(y_test.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHbhxbJFU8fT"
      },
      "source": [
        "## 1.3. Feature scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T1oT_D-U8fU"
      },
      "source": [
        "Min-max normalization and standardization are two popular feature scaling methods.\n",
        "\n",
        "- Min-max normalization scales the features to the interval $[0, 1]$.\n",
        "- Standardization makes the features have zero mean and unit variance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F320GXNdU8fV",
        "outputId": "8c9206ab-9e61-4a69-9a44-2a8df4c12558"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.35294118 0.74371859 0.59016393 ... 0.50074514 0.23441503 0.48333333]\n",
            " [0.05882353 0.42713568 0.54098361 ... 0.39642326 0.11656704 0.16666667]\n",
            " [0.47058824 0.91959799 0.52459016 ... 0.34724292 0.25362938 0.18333333]\n",
            " ...\n",
            " [0.29411765 0.6080402  0.59016393 ... 0.39046202 0.07130658 0.15      ]\n",
            " [0.05882353 0.63316583 0.49180328 ... 0.44858422 0.11571307 0.43333333]\n",
            " [0.05882353 0.46733668 0.57377049 ... 0.45305516 0.10119556 0.03333333]]\n",
            "max = \n",
            "[1. 1. 1. 1. 1. 1. 1. 1.]\n",
            "min = \n",
            "[0. 0. 0. 0. 0. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "# Min-Max Normalization\n",
        "d = x.shape[1]\n",
        "xmin = np.min(x, axis=0).reshape(1, d)\n",
        "xmax = np.max(x, axis=0).reshape(1, d)\n",
        "xnew = (x - xmin) / (xmax - xmin)\n",
        "\n",
        "print(xnew)\n",
        "\n",
        "print('max = ')\n",
        "print(np.max(xnew, axis=0))\n",
        "\n",
        "print('min = ')\n",
        "print(np.min(xnew, axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLkMWyCOU8fZ",
        "outputId": "7a2bedda-cc02-4855-fe70-7a4bf690ddcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xnew = \n",
            "[[ 0.63994726  0.84832379  0.14964075 ...  0.20401252  0.46849198\n",
            "   1.4259954 ]\n",
            " [-0.84488505 -1.12339636 -0.16054575 ... -0.68442195 -0.36506078\n",
            "  -0.19067191]\n",
            " [ 1.23388019  1.94372388 -0.26394125 ... -1.10325559  0.60439732\n",
            "  -0.10558415]\n",
            " ...\n",
            " [ 0.3429808   0.00330087  0.14964075 ... -0.73518952 -0.68519336\n",
            "  -0.27575966]\n",
            " [-0.84488505  0.1597866  -0.47073225 ... -0.24020459 -0.37110101\n",
            "   1.17073215]\n",
            " [-0.84488505 -0.8730192   0.04624525 ... -0.20212882 -0.47378505\n",
            "  -0.87137393]]\n",
            "mean = \n",
            "[-7.74843153e-17  3.61400724e-18 -1.32724416e-17  7.76288755e-17\n",
            " -5.49329101e-17  5.12683067e-15  1.92438658e-15  2.19297959e-16]\n",
            "std = \n",
            "[1. 1. 1. 1. 1. 1. 1. 1.]\n"
          ]
        }
      ],
      "source": [
        "# Standardization\n",
        "\n",
        "d = x.shape[1]\n",
        "mu = np.mean(x, axis=0).reshape(1, d)\n",
        "sig = np.std(x, axis=0).reshape(1, d)\n",
        "xnew = (x - mu) / sig\n",
        "\n",
        "print('xnew = ')\n",
        "print(xnew)\n",
        "\n",
        "print('mean = ')\n",
        "print(np.mean(xnew, axis=0))\n",
        "\n",
        "print('std = ')\n",
        "print(np.std(xnew, axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODJv-cZGU8fg"
      },
      "source": [
        "### In this homework, we use the standardization to trainsform both training and test features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh16BVL1U8fh",
        "outputId": "7c847f51-06a9-43c9-a601-8eb9b93d9831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test mean = \n",
            "[-0.01728271  0.21518297  0.11572014  0.00615854 -0.09787213  0.00449861\n",
            " -0.06743849  0.01112509]\n",
            "test std = \n",
            "[0.88225663 0.94605568 0.78874768 1.04421846 0.94337803 0.88991846\n",
            " 1.14471327 0.96035844]\n"
          ]
        }
      ],
      "source": [
        "# Standardization\n",
        "\n",
        "# calculate mu and sig using the training set\n",
        "d = x_train.shape[1]\n",
        "mu = np.mean(x_train, axis=0).reshape(1, d)\n",
        "sig = np.std(x_train, axis=0).reshape(1, d)\n",
        "\n",
        "# transform the training features\n",
        "x_train = (x_train - mu) / sig\n",
        "\n",
        "# transform the test features\n",
        "x_test = (x_test - mu) / sig\n",
        "\n",
        "\n",
        "print('test mean = ')\n",
        "print(np.mean(x_test, axis=0))\n",
        "\n",
        "print('test std = ')\n",
        "print(np.std(x_test, axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBn7Lj6AU8fp"
      },
      "source": [
        "# 2. Logistic regression model\n",
        "## Define the sigmoid function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "aK2j8pVKQ8OT"
      },
      "outputs": [],
      "source": [
        "def _sigmoid(z):\n",
        "    # Sigmoid function can be used to calculate probability.\n",
        "    # To avoid overflow, minimum/maximum output value is set.\n",
        "    return np.clip(1 / (1.0 + np.exp(-z)), 1e-8, 1 - (1e-8))\n",
        "\n",
        "def _f(X, w, b):\n",
        "    # This is the logistic regression function, parameterized by w and b\n",
        "    #\n",
        "    # Arguements:\n",
        "    #     X: input data, shape = [n or batch_size, data_dimension]\n",
        "    #     w: weight vector, shape = [data_dimension, ]\n",
        "    #     b: bias, scalar\n",
        "    # Output:\n",
        "    #     predicted probability of each row of X being positively labeled, shape = [n or batch_size, ]\n",
        "    return _sigmoid(np.matmul(X, w) + b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpld_Qg-RB1a"
      },
      "source": [
        "The objective function is $L(\\mathbf{w}; \\mathbf{X}, \\mathbf{y})=\\sum_{i=1}^n -[y_i \\log \\hat y_i + (1-y_i)\\log (1-\\hat y_i)]$, where $\\hat y_i = \\sigma (\\mathbf{w}^T \\mathbf{x}_i +b)$.\n",
        "\n",
        "<font color='red'> **rubic={20 points}** </font> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "7me0eR0cU8fq"
      },
      "outputs": [],
      "source": [
        "def _cross_entropy_loss(y_pred, Y_label):\n",
        "    \n",
        "    # This function computes the cross entropy.\n",
        "    #\n",
        "    # Arguements:\n",
        "    #     y_pred: probabilistic predictions, float vector\n",
        "    #     Y_label: ground truth labels,  vector\n",
        "    # Output:\n",
        "    #     cross entropy: scalar\n",
        "\n",
        "    ## write your code here. You CANNOT use for loop here.\n",
        "    \n",
        "    cross_entropy = np.sum(-( Y_label * (np.log(y_pred)) + (1 - (Y_label)) * np.log(1 - (y_pred)) )) \n",
        "    \n",
        "    return cross_entropy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhSa5351U8ft",
        "outputId": "5f7f274a-b03c-4fd6-82dc-ae817e892078"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial objective function value = 426.2855160443664\n"
          ]
        }
      ],
      "source": [
        "# initialize w, b\n",
        "d = x_train.shape[1]\n",
        "w = np.zeros(d)\n",
        "b = np.zeros(1)\n",
        "# evaluate the objective function value at w\n",
        "y_pred = _f(x_train, w, b)\n",
        "objval0 = _cross_entropy_loss(y_pred, y_train)\n",
        "print('Initial objective function value = ' + str(objval0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKtSRP2lU8fx"
      },
      "source": [
        "# 3. Numerical optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UH9nycupU8fx"
      },
      "source": [
        "## 3.1. Calculate the full gradient\n",
        "\n",
        "The gradient at $w$ is $g = \\frac{1}{n} \\sum_{i=1}^n [\\sigma (\\mathbf{w}^T \\mathbf{x}_i + b)-y_i]\\mathbf{x}_i$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "kWp8JOYBOFZX"
      },
      "outputs": [],
      "source": [
        "# Calculate the gradient\n",
        "# Inputs:\n",
        "#     X: n-by-d matrix\n",
        "#     Y_label: n-by-1 matrix\n",
        "#     w: d-by-1 matrix\n",
        "#     b: scalar\n",
        "# Return:\n",
        "#     w_grad: d-by-1 matrix, full gradient\n",
        "#     b_grad: scalar\n",
        "def _gradient(X, Y_label, w, b):\n",
        "    # This function computes the gradient of cross entropy loss with respect to weight w and bias b.\n",
        "    y_pred = _f(X, w, b)\n",
        "    pred_error = y_pred - Y_label\n",
        "    w_grad = np.mean(pred_error * X.T, 1)\n",
        "    b_grad = np.mean(pred_error)\n",
        "    return w_grad, b_grad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2zIXNwnU8f2"
      },
      "source": [
        "## 3.2. Gradient descent\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "1RBVx_34U8f2"
      },
      "outputs": [],
      "source": [
        "# Gradient descent for solving logistic regression\n",
        "# Inputs:\n",
        "#     x_train: n-by-d matrix\n",
        "#     y_train: n-by-1 matrix\n",
        "#     stepsize: scalar\n",
        "#     max_iter: integer, the maximal iterations\n",
        "# Return:\n",
        "#     w: d-by-1 matrix, the solution\n",
        "#     b: scalr, the solution\n",
        "#     objvals: a record of each epoch's objective value\n",
        "def grad_descent(x_train, y_train, w, b, stepsize, max_iter=150):\n",
        "    n, d = x_train.shape\n",
        "    objvals = np.zeros(max_iter) # store the objective values\n",
        "    \n",
        "    for t in range(max_iter):\n",
        "        y_pred = _f(x_train, w, b)\n",
        "        objval = _cross_entropy_loss(y_pred, y_train)\n",
        "        objvals[t] = objval/n\n",
        "        print('Objective value at t=' + str(t) + ' is ' + str(objval/n))\n",
        "        w_grad, b_grad = _gradient(x_train, y_train, w, b)\n",
        "        w -= stepsize * w_grad\n",
        "        b -= stepsize * b_grad\n",
        "    stepsize *= 0.9 # decrease step size\n",
        "    \n",
        "    return w, b, objvals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNZqy-TbU8f7",
        "outputId": "a5247a34-c60c-45c5-ff22-f7ddc1086a13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Objective value at t=0 is 0.6931471805599453\n",
            "Objective value at t=1 is 0.6674933594562708\n",
            "Objective value at t=2 is 0.6458192748474948\n",
            "Objective value at t=3 is 0.6273974180422861\n",
            "Objective value at t=4 is 0.6116290580131932\n",
            "Objective value at t=5 is 0.598030898709449\n",
            "Objective value at t=6 is 0.5862165577891675\n",
            "Objective value at t=7 is 0.5758780441374336\n",
            "Objective value at t=8 is 0.5667695067924607\n",
            "Objective value at t=9 is 0.5586938801184572\n",
            "Objective value at t=10 is 0.5514922838816346\n",
            "Objective value at t=11 is 0.5450357604910695\n",
            "Objective value at t=12 is 0.5392188873120096\n",
            "Objective value at t=13 is 0.5339548502550142\n",
            "Objective value at t=14 is 0.5291716394787829\n",
            "Objective value at t=15 is 0.524809101184558\n",
            "Objective value at t=16 is 0.5208166415695856\n",
            "Objective value at t=17 is 0.517151428382305\n",
            "Objective value at t=18 is 0.5137769734946603\n",
            "Objective value at t=19 is 0.5106620086044198\n",
            "Objective value at t=20 is 0.5077795876840351\n",
            "Objective value at t=21 is 0.5051063658547315\n",
            "Objective value at t=22 is 0.502622016364146\n",
            "Objective value at t=23 is 0.5003087563310623\n",
            "Objective value at t=24 is 0.4981509586734979\n",
            "Objective value at t=25 is 0.4961348327343087\n",
            "Objective value at t=26 is 0.4942481599866212\n",
            "Objective value at t=27 is 0.49248007415225814\n",
            "Objective value at t=28 is 0.4908208773298891\n",
            "Objective value at t=29 is 0.48926188547572\n",
            "Objective value at t=30 is 0.48779529793394727\n",
            "Objective value at t=31 is 0.4864140867705947\n",
            "Objective value at t=32 is 0.4851119024927464\n",
            "Objective value at t=33 is 0.48388299338822877\n",
            "Objective value at t=34 is 0.4827221362382451\n",
            "Objective value at t=35 is 0.4816245765675276\n",
            "Objective value at t=36 is 0.4805859769262928\n",
            "Objective value at t=37 is 0.4796023719633742\n",
            "Objective value at t=38 is 0.4786701292639828\n",
            "Objective value at t=39 is 0.4777859150992024\n",
            "Objective value at t=40 is 0.47694666437578975\n",
            "Objective value at t=41 is 0.4761495541905666\n",
            "Objective value at t=42 is 0.47539198048872167\n",
            "Objective value at t=43 is 0.4746715374036954\n",
            "Objective value at t=44 is 0.4739859989211585\n",
            "Objective value at t=45 is 0.4733333025634514\n",
            "Objective value at t=46 is 0.47271153483574363\n",
            "Objective value at t=47 is 0.47211891821271573\n",
            "Objective value at t=48 is 0.4715537994760819\n",
            "Objective value at t=49 is 0.4710146392397928\n",
            "Objective value at t=50 is 0.4705000025221733\n",
            "Objective value at t=51 is 0.4700085502432279\n",
            "Objective value at t=52 is 0.4695390315414804\n",
            "Objective value at t=53 is 0.46909027681846505\n",
            "Objective value at t=54 is 0.4686611914307315\n",
            "Objective value at t=55 is 0.4682507499593037\n",
            "Objective value at t=56 is 0.4678579909951824\n",
            "Objective value at t=57 is 0.46748201238694015\n",
            "Objective value at t=58 is 0.4671219669029018\n",
            "Objective value at t=59 is 0.46677705826598004\n",
            "Objective value at t=60 is 0.4664465375240802\n",
            "Objective value at t=61 is 0.46612969972320606\n",
            "Objective value at t=62 is 0.4658258808540689\n",
            "Objective value at t=63 is 0.46553445504622515\n",
            "Objective value at t=64 is 0.4652548319865746\n",
            "Objective value at t=65 is 0.4649864545415311\n",
            "Objective value at t=66 is 0.46472879656434923\n",
            "Objective value at t=67 is 0.46448136087100966\n",
            "Objective value at t=68 is 0.4642436773697601\n",
            "Objective value at t=69 is 0.46401530133090846\n",
            "Objective value at t=70 is 0.4637958117847952\n",
            "Objective value at t=71 is 0.4635848100370506\n",
            "Objective value at t=72 is 0.46338191829129977\n",
            "Objective value at t=73 is 0.4631867783704064\n",
            "Objective value at t=74 is 0.4629990505281932\n",
            "Objective value at t=75 is 0.4628184123443171\n",
            "Objective value at t=76 is 0.4626445576956521\n",
            "Objective value at t=77 is 0.4624771957981329\n",
            "Objective value at t=78 is 0.4623160503135536\n",
            "Objective value at t=79 is 0.46216085851629984\n",
            "Objective value at t=80 is 0.4620113705154341\n",
            "Objective value at t=81 is 0.4618673485279456\n",
            "Objective value at t=82 is 0.4617285661993362\n",
            "Objective value at t=83 is 0.4615948079680364\n",
            "Objective value at t=84 is 0.46146586847043414\n",
            "Objective value at t=85 is 0.4613415519835714\n",
            "Objective value at t=86 is 0.461221671902798\n",
            "Objective value at t=87 is 0.46110605025189383\n",
            "Objective value at t=88 is 0.4609945172233699\n",
            "Objective value at t=89 is 0.4608869107468398\n",
            "Objective value at t=90 is 0.4607830760835163\n",
            "Objective value at t=91 is 0.4606828654450438\n",
            "Objective value at t=92 is 0.46058613763500894\n",
            "Objective value at t=93 is 0.4604927577116036\n",
            "Objective value at t=94 is 0.4604025966700248\n",
            "Objective value at t=95 is 0.4603155311433073\n",
            "Objective value at t=96 is 0.4602314431203741\n",
            "Objective value at t=97 is 0.460150219680189\n",
            "Objective value at t=98 is 0.4600717527409663\n",
            "Objective value at t=99 is 0.45999593882347617\n",
            "Objective value at t=100 is 0.45992267882755056\n",
            "Objective value at t=101 is 0.45985187782095427\n",
            "Objective value at t=102 is 0.45978344483985206\n",
            "Objective value at t=103 is 0.4597172927001505\n",
            "Objective value at t=104 is 0.4596533378190443\n",
            "Objective value at t=105 is 0.4595915000461468\n",
            "Objective value at t=106 is 0.45953170250361935\n",
            "Objective value at t=107 is 0.45947387143476337\n",
            "Objective value at t=108 is 0.4594179360605644\n",
            "Objective value at t=109 is 0.4593638284437217\n",
            "Objective value at t=110 is 0.45931148335971916\n",
            "Objective value at t=111 is 0.45926083817452923\n",
            "Objective value at t=112 is 0.4592118327285624\n",
            "Objective value at t=113 is 0.45916440922650587\n",
            "Objective value at t=114 is 0.4591185121327113\n",
            "Objective value at t=115 is 0.4590740880718197\n",
            "Objective value at t=116 is 0.4590310857343263\n",
            "Objective value at t=117 is 0.4589894557868098\n",
            "Objective value at t=118 is 0.4589491507865657\n",
            "Objective value at t=119 is 0.4589101251004021\n",
            "Objective value at t=120 is 0.4588723348273683\n",
            "Objective value at t=121 is 0.45883573772520253\n",
            "Objective value at t=122 is 0.4588002931402965\n",
            "Objective value at t=123 is 0.45876596194099073\n",
            "Objective value at t=124 is 0.45873270645401804\n",
            "Objective value at t=125 is 0.4587004904039328\n",
            "Objective value at t=126 is 0.45866927885536546\n",
            "Objective value at t=127 is 0.45863903815795487\n",
            "Objective value at t=128 is 0.45860973589382137\n",
            "Objective value at t=129 is 0.4585813408274449\n",
            "Objective value at t=130 is 0.45855382285782864\n",
            "Objective value at t=131 is 0.4585271529728289\n",
            "Objective value at t=132 is 0.4585013032055429\n",
            "Objective value at t=133 is 0.4584762465926484\n",
            "Objective value at t=134 is 0.4584519571345997\n",
            "Objective value at t=135 is 0.4584284097575863\n",
            "Objective value at t=136 is 0.4584055802771669\n",
            "Objective value at t=137 is 0.4583834453634958\n",
            "Objective value at t=138 is 0.45836198250806465\n",
            "Objective value at t=139 is 0.4583411699918854\n",
            "Objective value at t=140 is 0.4583209868550443\n",
            "Objective value at t=141 is 0.45830141286756126\n",
            "Objective value at t=142 is 0.4582824285014926\n",
            "Objective value at t=143 is 0.45826401490421603\n",
            "Objective value at t=144 is 0.4582461538728456\n",
            "Objective value at t=145 is 0.45822882782971985\n",
            "Objective value at t=146 is 0.4582120197989135\n",
            "Objective value at t=147 is 0.45819571338372833\n",
            "Objective value at t=148 is 0.45817989274511367\n",
            "Objective value at t=149 is 0.45816454258097533\n"
          ]
        }
      ],
      "source": [
        "# example\n",
        "d = x_train.shape[1]\n",
        "w = np.zeros(d)\n",
        "b = np.zeros(1)\n",
        "stepsize = 0.2\n",
        "w, b, objvals_gd = grad_descent(x_train, y_train, w, b, stepsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVrjVsv0U8f-"
      },
      "source": [
        "## 3.3. Stochastic gradient descent (SGD)\n",
        "\n",
        "Define $L_i(\\mathbf{w}; \\mathbf{x}, y)= -[y_i \\log \\hat y_i + (1-y_i)\\log (1-\\hat y_i)]$, where $\\hat y_i = \\sigma (\\mathbf{w}^T \\mathbf{x}_i +b)$.\n",
        "\n",
        "The stochastic gradient at $w$ is $g_i = \\frac{\\partial L_i }{ \\partial w} = [\\sigma (\\mathbf{w}^T \\mathbf{x}_i + b)-y_i]\\mathbf{x}_i$.\n",
        "\n",
        "<font color='red'> **rubic={30 points}** </font> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "RwJeIIOHU8f-"
      },
      "outputs": [],
      "source": [
        "# Calculate the objective L_i and the gradient of L_i\n",
        "# Inputs (you can revise the inputs of this function):\n",
        "#     xi: 1-by-d matrix\n",
        "#     yi: scalar\n",
        "#     w: d-by-1 matrix\n",
        "#     b: scalar\n",
        "# Return:\n",
        "#     w_grad: d-by-1 matrix, gradient of L_i with respect to w\n",
        "#     b_grad: scalr, gradient of L_i with respect to b\n",
        "def stochastic_objective_gradient(xi, yi, w, b):\n",
        "    y_pred = _f(xi, w, b)\n",
        "    pred_error = y_pred - yi\n",
        "    w_grad = np.asarray(pred_error * xi.T)\n",
        "    b_grad = pred_error\n",
        "\n",
        "    return w_grad, b_grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "id": "BTZtZdhbU8gE"
      },
      "outputs": [],
      "source": [
        "# SGD for solving logistic regression\n",
        "# Inputs:\n",
        "#     x_train: n-by-d matrix\n",
        "#     y_train: n-by-1 matrix\n",
        "#     w: d-by-1 matrix, initialization of w\n",
        "#     b: scalr, initialization of b\n",
        "#     stepsize: scalar\n",
        "#     max_epoch: integer, the maximal epochs\n",
        "# Return:\n",
        "#     w: the solution\n",
        "#     b: the solution\n",
        "#     objvals: record of each epoch's objective value\n",
        "def sgd(x_train, y_train, w, b, stepsize, max_epoch=150):\n",
        "    n, d = x_train.shape\n",
        "    objvals = np.zeros(max_epoch) # store the objective values\n",
        "    for t in range(max_epoch):\n",
        "        # randomly shuffle the samples\n",
        "        rand_indices = np.random.permutation(n)\n",
        "        x_rand = x_train[rand_indices, :]\n",
        "        y_rand = y_train[rand_indices]\n",
        "        \n",
        "        objval = 0 # accumulate the objective values\n",
        "        for i in range(n):\n",
        "            xi = x_rand[i, :] # 1-by-d matrix\n",
        "            yi = float(y_rand[i]) # scalar\n",
        "            y_pred = _f(xi, w, b)\n",
        "            obj = float(_cross_entropy_loss(y_pred, yi))\n",
        "            w_grad, b_grad = stochastic_objective_gradient(xi, yi, w, b)\n",
        "            objval += obj\n",
        "            w -= stepsize * w_grad\n",
        "            b -= stepsize * b_grad\n",
        "        \n",
        "        stepsize *= 0.9 # decrease step size\n",
        "        objvals[t] = objval/n\n",
        "        print('Objective value at epoch t=' + str(t) + ' is ' + str(objval/n))\n",
        "    \n",
        "    return w, b, objvals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iWwrX2IUU8gH",
        "outputId": "c63594e5-64a2-4bca-980c-5bb9c7d6d94a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Objective value at epoch t=0 is 0.5655778159751734\n",
            "Objective value at epoch t=1 is 0.5372056510237724\n",
            "Objective value at epoch t=2 is 0.5479375407432525\n",
            "Objective value at epoch t=3 is 0.5260003825464782\n",
            "Objective value at epoch t=4 is 0.518071646545653\n",
            "Objective value at epoch t=5 is 0.5104025225358542\n",
            "Objective value at epoch t=6 is 0.508208741619286\n",
            "Objective value at epoch t=7 is 0.5119798589677133\n",
            "Objective value at epoch t=8 is 0.4974004801824455\n",
            "Objective value at epoch t=9 is 0.4946912958779277\n",
            "Objective value at epoch t=10 is 0.48471146500869766\n",
            "Objective value at epoch t=11 is 0.4830201980190446\n",
            "Objective value at epoch t=12 is 0.4868150722564176\n",
            "Objective value at epoch t=13 is 0.4790236472727782\n",
            "Objective value at epoch t=14 is 0.48341184764290085\n",
            "Objective value at epoch t=15 is 0.4764972722473233\n",
            "Objective value at epoch t=16 is 0.47445478956645043\n",
            "Objective value at epoch t=17 is 0.477437891232908\n",
            "Objective value at epoch t=18 is 0.476202372345\n",
            "Objective value at epoch t=19 is 0.47291843306081355\n",
            "Objective value at epoch t=20 is 0.4716914567419277\n",
            "Objective value at epoch t=21 is 0.47052446301309475\n",
            "Objective value at epoch t=22 is 0.46704313601029396\n",
            "Objective value at epoch t=23 is 0.4675969211852802\n",
            "Objective value at epoch t=24 is 0.46626906688285585\n",
            "Objective value at epoch t=25 is 0.46365738378194865\n",
            "Objective value at epoch t=26 is 0.46636280103031813\n",
            "Objective value at epoch t=27 is 0.46443246863660753\n",
            "Objective value at epoch t=28 is 0.4625430555094798\n",
            "Objective value at epoch t=29 is 0.46367481889650747\n",
            "Objective value at epoch t=30 is 0.46292850239818395\n",
            "Objective value at epoch t=31 is 0.46240713456352783\n",
            "Objective value at epoch t=32 is 0.46144702477457444\n",
            "Objective value at epoch t=33 is 0.46150804641490695\n",
            "Objective value at epoch t=34 is 0.4612336183515667\n",
            "Objective value at epoch t=35 is 0.4608940456695771\n",
            "Objective value at epoch t=36 is 0.46059595597224595\n",
            "Objective value at epoch t=37 is 0.4602081840733257\n",
            "Objective value at epoch t=38 is 0.4598682683101285\n",
            "Objective value at epoch t=39 is 0.4597613183127432\n",
            "Objective value at epoch t=40 is 0.45957289861801726\n",
            "Objective value at epoch t=41 is 0.45942828871646446\n",
            "Objective value at epoch t=42 is 0.45922606577808806\n",
            "Objective value at epoch t=43 is 0.45904849879055826\n",
            "Objective value at epoch t=44 is 0.45894088178821335\n",
            "Objective value at epoch t=45 is 0.4588132613403478\n",
            "Objective value at epoch t=46 is 0.4586983186479967\n",
            "Objective value at epoch t=47 is 0.45858621331155375\n",
            "Objective value at epoch t=48 is 0.45847476694913886\n",
            "Objective value at epoch t=49 is 0.4584057424028609\n",
            "Objective value at epoch t=50 is 0.4583350416614229\n",
            "Objective value at epoch t=51 is 0.45826005206845905\n",
            "Objective value at epoch t=52 is 0.4581934704927768\n",
            "Objective value at epoch t=53 is 0.4581409302707378\n",
            "Objective value at epoch t=54 is 0.4580966090583245\n",
            "Objective value at epoch t=55 is 0.4580477337046453\n",
            "Objective value at epoch t=56 is 0.4580110367436581\n",
            "Objective value at epoch t=57 is 0.45797239764766406\n",
            "Objective value at epoch t=58 is 0.457939684055157\n",
            "Objective value at epoch t=59 is 0.45791038888717017\n",
            "Objective value at epoch t=60 is 0.45788233785379856\n",
            "Objective value at epoch t=61 is 0.45785959549080396\n",
            "Objective value at epoch t=62 is 0.45783768338260267\n",
            "Objective value at epoch t=63 is 0.4578180153653315\n",
            "Objective value at epoch t=64 is 0.4578003434632581\n",
            "Objective value at epoch t=65 is 0.4577839935717975\n",
            "Objective value at epoch t=66 is 0.4577697854914362\n",
            "Objective value at epoch t=67 is 0.45775676867091036\n",
            "Objective value at epoch t=68 is 0.45774525420554607\n",
            "Objective value at epoch t=69 is 0.45773458766648273\n",
            "Objective value at epoch t=70 is 0.45772539445792365\n",
            "Objective value at epoch t=71 is 0.4577168052290689\n",
            "Objective value at epoch t=72 is 0.45770919893507644\n",
            "Objective value at epoch t=73 is 0.4577022758701395\n",
            "Objective value at epoch t=74 is 0.4576960961235841\n",
            "Objective value at epoch t=75 is 0.45769051664554733\n",
            "Objective value at epoch t=76 is 0.45768551891889886\n",
            "Objective value at epoch t=77 is 0.45768097650591105\n",
            "Objective value at epoch t=78 is 0.4576769248599727\n",
            "Objective value at epoch t=79 is 0.4576732472470716\n",
            "Objective value at epoch t=80 is 0.45766996363118767\n",
            "Objective value at epoch t=81 is 0.45766700005268834\n",
            "Objective value at epoch t=82 is 0.45766432324047146\n",
            "Objective value at epoch t=83 is 0.45766192932099015\n",
            "Objective value at epoch t=84 is 0.45765975281221827\n",
            "Objective value at epoch t=85 is 0.4576578161019999\n",
            "Objective value at epoch t=86 is 0.45765606203468134\n",
            "Objective value at epoch t=87 is 0.4576544844707501\n",
            "Objective value at epoch t=88 is 0.45765305926253674\n",
            "Objective value at epoch t=89 is 0.45765178401466544\n",
            "Objective value at epoch t=90 is 0.4576506345862367\n",
            "Objective value at epoch t=91 is 0.457649600470368\n",
            "Objective value at epoch t=92 is 0.4576486692624598\n",
            "Objective value at epoch t=93 is 0.45764783072519755\n",
            "Objective value at epoch t=94 is 0.4576470758654827\n",
            "Objective value at epoch t=95 is 0.45764639645082716\n",
            "Objective value at epoch t=96 is 0.45764578530263156\n",
            "Objective value at epoch t=97 is 0.4576452349549156\n",
            "Objective value at epoch t=98 is 0.45764473992071314\n",
            "Objective value at epoch t=99 is 0.457644294033207\n",
            "Objective value at epoch t=100 is 0.4576438931335167\n",
            "Objective value at epoch t=101 is 0.45764353199273383\n",
            "Objective value at epoch t=102 is 0.45764320712940654\n",
            "Objective value at epoch t=103 is 0.45764291462322937\n",
            "Objective value at epoch t=104 is 0.45764265136265597\n",
            "Objective value at epoch t=105 is 0.45764241461664734\n",
            "Objective value at epoch t=106 is 0.4576422013635181\n",
            "Objective value at epoch t=107 is 0.4576420095039413\n",
            "Objective value at epoch t=108 is 0.4576418368112916\n",
            "Objective value at epoch t=109 is 0.45764168140290296\n",
            "Objective value at epoch t=110 is 0.4576415415340146\n",
            "Objective value at epoch t=111 is 0.45764141561097993\n",
            "Objective value at epoch t=112 is 0.45764130231383454\n",
            "Objective value at epoch t=113 is 0.45764120033481903\n",
            "Objective value at epoch t=114 is 0.45764110857766377\n",
            "Objective value at epoch t=115 is 0.45764102596426237\n",
            "Objective value at epoch t=116 is 0.45764095163476826\n",
            "Objective value at epoch t=117 is 0.4576408847289107\n",
            "Objective value at epoch t=118 is 0.4576408245145049\n",
            "Objective value at epoch t=119 is 0.45764077031971295\n",
            "Objective value at epoch t=120 is 0.45764072154512137\n",
            "Objective value at epoch t=121 is 0.4576406776501834\n",
            "Objective value at epoch t=122 is 0.4576406381398653\n",
            "Objective value at epoch t=123 is 0.45764060258430705\n",
            "Objective value at epoch t=124 is 0.45764057058369384\n",
            "Objective value at epoch t=125 is 0.4576405417827824\n",
            "Objective value at epoch t=126 is 0.4576405158618419\n",
            "Objective value at epoch t=127 is 0.45764049253250544\n",
            "Objective value at epoch t=128 is 0.45764047153669046\n",
            "Objective value at epoch t=129 is 0.45764045263865416\n",
            "Objective value at epoch t=130 is 0.4576404356329321\n",
            "Objective value at epoch t=131 is 0.4576404203264054\n",
            "Objective value at epoch t=132 is 0.4576404065508819\n",
            "Objective value at epoch t=133 is 0.4576403941535904\n",
            "Objective value at epoch t=134 is 0.4576403829953011\n",
            "Objective value at epoch t=135 is 0.4576403729530261\n",
            "Objective value at epoch t=136 is 0.4576403639148936\n",
            "Objective value at epoch t=137 is 0.45764035578052503\n",
            "Objective value at epoch t=138 is 0.4576403484597293\n",
            "Objective value at epoch t=139 is 0.4576403418708411\n",
            "Objective value at epoch t=140 is 0.4576403359409269\n",
            "Objective value at epoch t=141 is 0.4576403306040363\n",
            "Objective value at epoch t=142 is 0.457640325800783\n",
            "Objective value at epoch t=143 is 0.457640321477849\n",
            "Objective value at epoch t=144 is 0.4576403175872147\n",
            "Objective value at epoch t=145 is 0.45764031408565303\n",
            "Objective value at epoch t=146 is 0.45764031093425206\n",
            "Objective value at epoch t=147 is 0.457640308097976\n",
            "Objective value at epoch t=148 is 0.45764030554533375\n",
            "Objective value at epoch t=149 is 0.4576403032479667\n"
          ]
        }
      ],
      "source": [
        "# example\n",
        "# initialize w, b\n",
        "d = x_train.shape[1]\n",
        "w = np.zeros(d)\n",
        "b = np.zeros(1)\n",
        "stepsize = 0.2\n",
        "w, b, objvals_sgd = sgd(x_train, y_train, w, b, stepsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYKci7dWU8gN"
      },
      "source": [
        "## 3.3. Mini-batch SGD\n",
        "\n",
        "Define $L_I(\\mathbf{w}; \\mathbf{X}, \\mathbf{y})= \\sum_{i \\in I} -[y_i \\log \\hat y_i + (1-y_i)\\log (1-\\hat y_i)]$, where $\\hat y_i = \\sigma (\\mathbf{w}^T \\mathbf{x}_i +b)$, and $I$ is a set containing $b$ indices randomly drawn from $\\{ 1, \\cdots , n \\}$ without replacement.\n",
        "\n",
        "\n",
        "\n",
        "The stochastic gradient at $w$ is $g_I =  \\sum_{i \\in I} [\\sigma (\\mathbf{w}^T \\mathbf{x}_i + b)-y_i]\\mathbf{x}_i$.\n",
        "\n",
        "<font color='red'> **rubic={50 points}** </font> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "6Owyb4YcXC09"
      },
      "outputs": [],
      "source": [
        "# mini_batch_SGD for solving logistic regression\n",
        "# Inputs:\n",
        "#     x_train: n-by-d matrix\n",
        "#     y_train: n-by-1 matrix\n",
        "#     w: d-by-1 matrix, initialization of w\n",
        "#     b: scalar, initialization of b\n",
        "#     stepsize: scalar\n",
        "#     batch_size: integer, the number of batch size\n",
        "#     max_epoch: integer, the maximal epochs\n",
        "# Return:\n",
        "#     w: the solution\n",
        "#     b: the solution\n",
        "#     objvals: record of each epoch's objective value\n",
        "import numpy\n",
        "def epoch(s, a, l):\n",
        "    idxArray = [i for i in range(len(a))]\n",
        "    numpy.random.shuffle(idxArray)\n",
        "    return [[a[numpy.array(idxArray[i: min(i + s, len(a))])], l[numpy.array(idxArray[i: min(i + s, len(a))])]]  for i in range(0,len(a), s)]\n",
        "    \n",
        "    \n",
        "def mini_batch_sgd(x_train, y_train, w, b, stepsize, batch_size=32, max_epoch=150):\n",
        "    n, d = x_train.shape\n",
        "    objvals = np.zeros(max_epoch)\n",
        "    \n",
        "    for t in range(max_epoch):\n",
        "      objval = 0 \n",
        "\n",
        "      ## write your code here\n",
        "      for X, Y in epoch(batch_size, x_train, y_train):\n",
        "          y_pred = _f(X, w, b)\n",
        "          DG, GG = _gradient(X, Y, w, b)\n",
        "          objval += _cross_entropy_loss(y_pred, Y)\n",
        "          w = w - stepsize * DG\n",
        "          b = b - stepsize * GG\n",
        "        \n",
        "      stepsize *= 0.9 \n",
        "      objvals[t] = objval/n\n",
        "      print('Objective value at epoch t=' + str(t) + ' is ' + str(objval/n))\n",
        "    \n",
        "    return w, b, objvals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkhRPei-a8l-",
        "outputId": "d6327c58-c080-46ce-fb26-ad138dfb4ba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Objective value at epoch t=0 is 0.5775974352263152\n",
            "Objective value at epoch t=1 is 0.49491102151260596\n",
            "Objective value at epoch t=2 is 0.4760571579931024\n",
            "Objective value at epoch t=3 is 0.4693481828469736\n",
            "Objective value at epoch t=4 is 0.4645570412555208\n",
            "Objective value at epoch t=5 is 0.46279143131321343\n",
            "Objective value at epoch t=6 is 0.46125268929698726\n",
            "Objective value at epoch t=7 is 0.4612293095928867\n",
            "Objective value at epoch t=8 is 0.4602783393942902\n",
            "Objective value at epoch t=9 is 0.4600457399069862\n",
            "Objective value at epoch t=10 is 0.45959002447185304\n",
            "Objective value at epoch t=11 is 0.459554459340907\n",
            "Objective value at epoch t=12 is 0.4596704394411856\n",
            "Objective value at epoch t=13 is 0.45896271107218695\n",
            "Objective value at epoch t=14 is 0.45904525007542973\n",
            "Objective value at epoch t=15 is 0.45893656838294306\n",
            "Objective value at epoch t=16 is 0.4588143607533298\n",
            "Objective value at epoch t=17 is 0.4585848855009432\n",
            "Objective value at epoch t=18 is 0.45858416579606454\n",
            "Objective value at epoch t=19 is 0.4584847997848674\n",
            "Objective value at epoch t=20 is 0.4584020762703169\n",
            "Objective value at epoch t=21 is 0.45832501658670854\n",
            "Objective value at epoch t=22 is 0.458321816902735\n",
            "Objective value at epoch t=23 is 0.4582324278583198\n",
            "Objective value at epoch t=24 is 0.45818377428001156\n",
            "Objective value at epoch t=25 is 0.4582399457795037\n",
            "Objective value at epoch t=26 is 0.45813869896831944\n",
            "Objective value at epoch t=27 is 0.4580588765241143\n",
            "Objective value at epoch t=28 is 0.4580417442437604\n",
            "Objective value at epoch t=29 is 0.4580408111247151\n",
            "Objective value at epoch t=30 is 0.45798971650175674\n",
            "Objective value at epoch t=31 is 0.4580264235760687\n",
            "Objective value at epoch t=32 is 0.4579643768662824\n",
            "Objective value at epoch t=33 is 0.4579353224867483\n",
            "Objective value at epoch t=34 is 0.45795730590218653\n",
            "Objective value at epoch t=35 is 0.45796349783305534\n",
            "Objective value at epoch t=36 is 0.4579387427476113\n",
            "Objective value at epoch t=37 is 0.45792623692032286\n",
            "Objective value at epoch t=38 is 0.4578855534955508\n",
            "Objective value at epoch t=39 is 0.4578918329247388\n",
            "Objective value at epoch t=40 is 0.457897757110695\n",
            "Objective value at epoch t=41 is 0.45789812909822464\n",
            "Objective value at epoch t=42 is 0.45787234841202673\n",
            "Objective value at epoch t=43 is 0.45786974357519333\n",
            "Objective value at epoch t=44 is 0.4578768121218392\n",
            "Objective value at epoch t=45 is 0.4578635161001498\n",
            "Objective value at epoch t=46 is 0.4578570041181182\n",
            "Objective value at epoch t=47 is 0.45784841812945853\n",
            "Objective value at epoch t=48 is 0.4578495516763194\n",
            "Objective value at epoch t=49 is 0.45783891936832327\n",
            "Objective value at epoch t=50 is 0.4578387993329321\n",
            "Objective value at epoch t=51 is 0.45783861947634175\n",
            "Objective value at epoch t=52 is 0.45783376586601215\n",
            "Objective value at epoch t=53 is 0.4578287379311437\n",
            "Objective value at epoch t=54 is 0.4578306447060621\n",
            "Objective value at epoch t=55 is 0.4578295824770438\n",
            "Objective value at epoch t=56 is 0.457826561134936\n",
            "Objective value at epoch t=57 is 0.4578256519303624\n",
            "Objective value at epoch t=58 is 0.45782388128868995\n",
            "Objective value at epoch t=59 is 0.45782419117183054\n",
            "Objective value at epoch t=60 is 0.4578224829034027\n",
            "Objective value at epoch t=61 is 0.4578217504808115\n",
            "Objective value at epoch t=62 is 0.4578187108814335\n",
            "Objective value at epoch t=63 is 0.45781867145061705\n",
            "Objective value at epoch t=64 is 0.4578199609072002\n",
            "Objective value at epoch t=65 is 0.4578186619904317\n",
            "Objective value at epoch t=66 is 0.4578176810300322\n",
            "Objective value at epoch t=67 is 0.45781755444642813\n",
            "Objective value at epoch t=68 is 0.45781692833206844\n",
            "Objective value at epoch t=69 is 0.4578165106976799\n",
            "Objective value at epoch t=70 is 0.4578163960155637\n",
            "Objective value at epoch t=71 is 0.45781575202003283\n",
            "Objective value at epoch t=72 is 0.45781531057902725\n",
            "Objective value at epoch t=73 is 0.4578154532725932\n",
            "Objective value at epoch t=74 is 0.45781483452330723\n",
            "Objective value at epoch t=75 is 0.4578145689964423\n",
            "Objective value at epoch t=76 is 0.4578148057620881\n",
            "Objective value at epoch t=77 is 0.4578143482828324\n",
            "Objective value at epoch t=78 is 0.45781439818022857\n",
            "Objective value at epoch t=79 is 0.4578142303062656\n",
            "Objective value at epoch t=80 is 0.45781391398305954\n",
            "Objective value at epoch t=81 is 0.4578140520194284\n",
            "Objective value at epoch t=82 is 0.4578136997839078\n",
            "Objective value at epoch t=83 is 0.4578136489723136\n",
            "Objective value at epoch t=84 is 0.4578134691746647\n",
            "Objective value at epoch t=85 is 0.45781340654147173\n",
            "Objective value at epoch t=86 is 0.457813366641715\n",
            "Objective value at epoch t=87 is 0.45781331415601856\n",
            "Objective value at epoch t=88 is 0.4578132435828126\n",
            "Objective value at epoch t=89 is 0.45781324926802136\n",
            "Objective value at epoch t=90 is 0.4578131713573215\n",
            "Objective value at epoch t=91 is 0.4578131819173656\n",
            "Objective value at epoch t=92 is 0.4578131672453852\n",
            "Objective value at epoch t=93 is 0.45781316667308536\n",
            "Objective value at epoch t=94 is 0.4578130999118899\n",
            "Objective value at epoch t=95 is 0.4578130824195668\n",
            "Objective value at epoch t=96 is 0.4578130448332841\n",
            "Objective value at epoch t=97 is 0.45781301971424077\n",
            "Objective value at epoch t=98 is 0.45781301874722763\n",
            "Objective value at epoch t=99 is 0.45781299829729644\n",
            "Objective value at epoch t=100 is 0.45781299592348357\n",
            "Objective value at epoch t=101 is 0.4578129664994244\n",
            "Objective value at epoch t=102 is 0.45781295337369243\n",
            "Objective value at epoch t=103 is 0.45781294080715235\n",
            "Objective value at epoch t=104 is 0.457812937573686\n",
            "Objective value at epoch t=105 is 0.45781292999045703\n",
            "Objective value at epoch t=106 is 0.45781291088823506\n",
            "Objective value at epoch t=107 is 0.4578129186072265\n",
            "Objective value at epoch t=108 is 0.457812911544837\n",
            "Objective value at epoch t=109 is 0.4578128958041754\n",
            "Objective value at epoch t=110 is 0.457812898585616\n",
            "Objective value at epoch t=111 is 0.4578128864581\n",
            "Objective value at epoch t=112 is 0.4578128825846357\n",
            "Objective value at epoch t=113 is 0.457812877802562\n",
            "Objective value at epoch t=114 is 0.4578128787432747\n",
            "Objective value at epoch t=115 is 0.4578128715219336\n",
            "Objective value at epoch t=116 is 0.45781286854263303\n",
            "Objective value at epoch t=117 is 0.45781286953128714\n",
            "Objective value at epoch t=118 is 0.45781286746219935\n",
            "Objective value at epoch t=119 is 0.4578128634218897\n",
            "Objective value at epoch t=120 is 0.45781286049464986\n",
            "Objective value at epoch t=121 is 0.4578128589997444\n",
            "Objective value at epoch t=122 is 0.4578128596080124\n",
            "Objective value at epoch t=123 is 0.4578128578107816\n",
            "Objective value at epoch t=124 is 0.4578128572231716\n",
            "Objective value at epoch t=125 is 0.4578128544075553\n",
            "Objective value at epoch t=126 is 0.4578128548123068\n",
            "Objective value at epoch t=127 is 0.4578128531950397\n",
            "Objective value at epoch t=128 is 0.45781285111802317\n",
            "Objective value at epoch t=129 is 0.4578128513295652\n",
            "Objective value at epoch t=130 is 0.4578128511008643\n",
            "Objective value at epoch t=131 is 0.45781285056284327\n",
            "Objective value at epoch t=132 is 0.45781285134594335\n",
            "Objective value at epoch t=133 is 0.4578128498008496\n",
            "Objective value at epoch t=134 is 0.45781284898522084\n",
            "Objective value at epoch t=135 is 0.45781284831487945\n",
            "Objective value at epoch t=136 is 0.4578128480217419\n",
            "Objective value at epoch t=137 is 0.45781284764138125\n",
            "Objective value at epoch t=138 is 0.45781284769386427\n",
            "Objective value at epoch t=139 is 0.4578128467398573\n",
            "Objective value at epoch t=140 is 0.45781284675025674\n",
            "Objective value at epoch t=141 is 0.45781284649259135\n",
            "Objective value at epoch t=142 is 0.457812846231399\n",
            "Objective value at epoch t=143 is 0.45781284639293596\n",
            "Objective value at epoch t=144 is 0.4578128459567415\n",
            "Objective value at epoch t=145 is 0.4578128460142491\n",
            "Objective value at epoch t=146 is 0.45781284585092424\n",
            "Objective value at epoch t=147 is 0.4578128456144756\n",
            "Objective value at epoch t=148 is 0.457812845504967\n",
            "Objective value at epoch t=149 is 0.45781284542187983\n"
          ]
        }
      ],
      "source": [
        "# example\n",
        "d = x_train.shape[1]\n",
        "w = np.zeros(d)\n",
        "b = np.zeros(1)\n",
        "stepsize = 0.2\n",
        "w, b, objvals_mini_sgd = mini_batch_sgd(x_train, y_train, w, b, stepsize)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJm0NM49U8gK"
      },
      "source": [
        "### Compare GD, SGD, and mini batch SGD\n",
        "\n",
        "Plot objective function values against epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "zrMngP3MU8gK",
        "outputId": "0863b281-299e-4158-a4a6-72c7b94c7dfa"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "\n",
        "epochs_gd = range(len(objvals_gd))\n",
        "epochs_sgd = range(len(objvals_sgd))\n",
        "epochs_mini_sgd = range(len(objvals_mini_sgd))\n",
        "\n",
        "line0, = plt.plot(epochs_gd, objvals_gd, '--b', LineWidth=2)\n",
        "line1, = plt.plot(epochs_sgd, objvals_sgd, '-r', LineWidth=2)\n",
        "line2, = plt.plot(epochs_mini_sgd, objvals_mini_sgd, '.-y', LineWidth=2)\n",
        "plt.xlabel('Epochs', FontSize=20)\n",
        "plt.ylabel('Objective Value', FontSize=20)\n",
        "plt.xticks(FontSize=16)\n",
        "plt.yticks(FontSize=16)\n",
        "plt.legend([line0, line1, line2], ['GD', 'SGD', 'batch SGD'], fontsize=20)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "fig.savefig('compare_gd_sgd.pdf', format='pdf', dpi=1200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzoBjLRuU8gN"
      },
      "source": [
        "# 4. Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "RxBpOpWtU8gO"
      },
      "outputs": [],
      "source": [
        "# Predict class label\n",
        "# Inputs:\n",
        "#     w: d-by-1 matrix\n",
        "#     X: m-by-d matrix\n",
        "# Return:\n",
        "#     f: m-by-1 matrix, the predictions\n",
        "def predict(w, X):\n",
        "    xw = np.dot(X, w)\n",
        "    f = np.sign(xw)\n",
        "    return f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-RJK4pnU8gQ",
        "outputId": "e200240a-fc9d-4875-bf28-2dab9ec7c4c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training classification error is 0.375609756097561\n"
          ]
        }
      ],
      "source": [
        "# evaluate training error\n",
        "f_train = predict(w, x_train)\n",
        "diff = np.abs(f_train - y_train) / 2\n",
        "error_train = np.mean(diff)\n",
        "print('Training classification error is ' + str(error_train))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "paDufW79U8gS",
        "outputId": "5146c4e6-46c5-4386-803c-83a83bb906ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test classification error is 0.37254901960784315\n"
          ]
        }
      ],
      "source": [
        "# evaluate test error\n",
        "f_test = predict(w, x_test)\n",
        "diff = np.abs(f_test - y_test) / 2\n",
        "error_test = np.mean(diff)\n",
        "print('Test classification error is ' + str(error_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BONUS**"
      ],
      "metadata": {
        "id": "PAHjz-CP9PnW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _gradient_reg(X, Y_label, w, b, i, batch_size, l):\n",
        "    y_pred = _f(X, w, b)\n",
        "    pred_error = y_pred - Y_label\n",
        "    if i == 0:\n",
        "        w_grad = np.mean(pred_error)\n",
        "    else:\n",
        "        w_grad = np.mean(pred_error * X.T, 1) + (1*w/batch_size)\n",
        "    b_grad = np.mean(pred_error)\n",
        "    return w_grad, b_grad\n",
        "\n",
        "import random\n",
        "def epoch(s, a, l):\n",
        "    idxArray = [i for i in range(len(a))]\n",
        "    numpy.random.shuffle(idxArray)\n",
        "    return [[a[numpy.array(idxArray[i: min(i + s, len(a))])], l[numpy.array(idxArray[i: min(i + s, len(a))])]]  for i in range(0,len(a), s)]\n",
        "\n",
        "    def mini_batch_sgd(x_train, y_train, w, b, stepsize, batch_size=32, max_epoch=150):\n",
        "         n, d = x_train.shape\n",
        "    objvals = np.zeros(max_epoch)\n",
        "    \n",
        "    for t in range(max_epoch):\n",
        "      objval = 0 \n",
        "\n",
        "      ## write your code here\n",
        "      for X, Y in epoch(batch_size, x_train, y_train):\n",
        "          y_pred = _f(X, w, b)\n",
        "          DG, GG = _gradient(X, Y, w, b)\n",
        "          objval += _cross_entropy_loss(y_pred, Y)\n",
        "          w = w - stepsize * DG\n",
        "          b = b - stepsize * GG\n",
        "        \n",
        "      stepsize *= 0.9 \n",
        "      objvals[t] = objval/n\n",
        "      print('Objective value at epoch t=' + str(t) + ' is ' + str(objval/n))\n",
        "    \n",
        "    return w, b, objvals\n",
        "\n"
      ],
      "metadata": {
        "id": "-DB8YmTUeywt"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcZlzcr8yGYZ"
      },
      "source": [
        "## Submission instructions \n",
        "\n",
        "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
        "\n",
        "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`.\n",
        "2. Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
        "3. Please keep your notebook clean and remove any throwaway code."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}