{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PQqHhZZHTALq"
   },
   "source": [
    "# Homework 1: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1LxhSTV3Fq6E"
   },
   "source": [
    "**Please type your name and A number here:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GdOh4SpaFq6F"
   },
   "outputs": [],
   "source": [
    "Name = \"Hari Chandana Kotnani\"\n",
    "assert Name != \"\", 'Please enter your name in the above quotation marks, thanks!'\n",
    "\n",
    "A_number = \"A02396013\"\n",
    "assert A_number != \"\", 'Please enter your A-number in the above quotation marks, thanks!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5XKY55fTALs"
   },
   "source": [
    "In this notebook we will use data on house sales in King County to predict house prices using both simple (one input) linear regression and multiple (multiple inputs) linear regression. You will:\n",
    "\n",
    "Part 1 (simple linear regression)\n",
    "* Complete functions to compute important summary statistics\n",
    "* Write a function to compute the Simple Linear Regression weights using the closed form solution\n",
    "* Write a function to make predictions of the output given the input feature\n",
    "* Turn the regression around to predict the input given the output\n",
    "* Compare two different models for predicting house prices\n",
    "\n",
    "Part 2 (multi-variable linear regression)\n",
    "* Add a constant column of 1's to a DataFrame to account for the intercept\n",
    "* Convert an DataFrame into a Numpy array\n",
    "* Write a predict_output() function using Numpy\n",
    "* Write a numpy function to compute the derivative of the regression weights with respect to a single feature\n",
    "* Write gradient descent function to compute the regression weights given an initial weight vector, step size and tolerance.\n",
    "* Use the gradient descent function to estimate regression weights for multiple features\n",
    "\n",
    "In this notebook you will be provided with some already complete code **as well as some code that you should complete yourself in order to answer quiz questions**. The code we provide to complete is optional and is there to assist you with solving the problems but feel free to ignore the helper code and write your own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZDYZpUtq6WL"
   },
   "source": [
    "# Part 1: Simple linear regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lgH7OLueTALt"
   },
   "source": [
    "# Fire up Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ay0elufhTALu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03nJ2eerTALv"
   },
   "source": [
    "# Load house sales data and split it into training and testing\n",
    "\n",
    "Dataset is from house sales in King County, the region where the city of Seattle, WA is located. We already split the data into training and testing so that everyone running this notebook gets the same results. In practice, you may check the function **train_test_split** from sklearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "OYERsGooTALv"
   },
   "outputs": [],
   "source": [
    "dtype_dict = {'bathrooms':float, 'waterfront':int, 'sqft_above':int, \n",
    "              'sqft_living15':float, 'grade':int, 'yr_renovated':int, \n",
    "              'price':float, 'bedrooms':float, 'zipcode':str, 'long':float, \n",
    "              'sqft_lot15':float, 'sqft_living':float, 'floors':str, 'condition':int,\n",
    "              'lat':float, 'date':str, 'sqft_basement':int, 'yr_built':int, 'id':str, 'sqft_lot':int, 'view':int}\n",
    "sales = pd.read_csv('kc_house_data.csv', dtype=dtype_dict)\n",
    "train_data = pd.read_csv('kc_house_train_data.csv', dtype=dtype_dict)\n",
    "test_data = pd.read_csv('kc_house_test_data.csv', dtype=dtype_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ruD6lVBwTALx"
   },
   "source": [
    "# Useful DataFrame summary functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G5P7sX8_TALx"
   },
   "source": [
    "In order to make use of the closed form solution as well as take advantage of pandas built in functions we will review some important ones. In particular:\n",
    "* Computing the sum of a DataFrame column\n",
    "* Computing the arithmetic average (mean) of a DataFrame column\n",
    "* multiplying DataFrame columns by constants\n",
    "* multiplying DataFrame columns by other DataFrame columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "skvoCz5yTALx",
    "outputId": "e305885c-b356-4d1f-c9bf-50b00ed24568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average price via method 1: 540088.1417665294\n",
      "average price via method 2: 540088.1417665294\n"
     ]
    }
   ],
   "source": [
    "# Let's compute the mean of the House Prices in King County in 2 different ways.\n",
    "prices = sales['price'] # extract the price column of the sales DatFrame -- this is now an DataFrame column\n",
    "square_feet = sales['sqft_lot']\n",
    "square_feet_living = sales['sqft_living']\n",
    "# recall that the arithmetic average (the mean) is the sum of the prices divided by the total number of houses:\n",
    "sum_prices = prices.sum()\n",
    "num_houses = len(prices) # when prices is an DataFrame column len() returns its length\n",
    "avg_price_1 = sum_prices/num_houses\n",
    "avg_price_2 = prices.mean() # if you just want the average, the .mean() function\n",
    "print(\"average price via method 1: \" + str(avg_price_1))\n",
    "print(\"average price via method 2: \" + str(avg_price_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7hB1LMgTALx"
   },
   "source": [
    "As we see we get the same answer both ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B1kPRzzTTALy",
    "outputId": "8872916d-a004-4be9-c245-bf3e405610b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the sum of price squared is: 9217325138472070.0\n"
     ]
    }
   ],
   "source": [
    "# if we want to multiply every price by 0.5 it's a simple as:\n",
    "half_prices = 0.5 * prices\n",
    "# Let's compute the sum of squares of price. We can multiply two DataFrame columns of the same length elementwise also with *\n",
    "prices_squared = prices*prices\n",
    "sum_prices_squared = prices_squared.sum() # price_squared is a DataFrame column of the squares and we want to add them up.\n",
    "print(\"the sum of price squared is: \" + str(sum_prices_squared))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTy_D1kJTALy"
   },
   "source": [
    "Aside: The python notation x.xxe+yy means x.xx \\* 10^(yy). e.g 100 = 10^2 = 1*10^2 = 1e2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIrUn4v4TALy"
   },
   "source": [
    "# Build a generic simple linear regression function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwNiPvS5TALy"
   },
   "source": [
    "Armed with these DataFrame functions we can use the closed form solution found from lecture to compute the slope and intercept for a simple linear regression on observations stored as DataFrame columns: input_feature, output.\n",
    "\n",
    "<font color='red'> **rubic={12 points}** </font> \n",
    "\n",
    "Complete the following function (or write your own) to compute the simple linear regression slope and intercept: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5Yai-ToITALz"
   },
   "outputs": [],
   "source": [
    "def simple_linear_regression(input_feature, output):\n",
    "    # compute the sum of input_feature and output\n",
    "    input_sum = input_feature.sum()\n",
    "    output_sum = output.sum()\n",
    "    input_mean = input_feature.mean()\n",
    "    output_mean = output.mean()\n",
    "    len_i = len(input_feature)       \n",
    "    # compute the product of the output and the input_feature and its sum\n",
    "    product_inp_oup = input_feature * output\n",
    "    product_inp_inp = input_feature * input_feature\n",
    "    sum_product_inp_oup = product_inp_oup.sum()\n",
    "    sum_product_inp_inp = product_inp_inp.sum()\n",
    "    mean_product_inp_oup = product_inp_oup.mean()\n",
    "    mean_product_inp_inp = product_inp_inp.mean()\n",
    "    # compute the squared value of the input_feature and its sum\n",
    "    i_sqrd = (input_feature * input_feature)\n",
    "    sum_i_sqrd = i_sqrd.sum()\n",
    "    #Slope:\n",
    "    numerator = sum_product_inp_oup - (1/len_i)*(input_sum * output_sum)\n",
    "    denominator = sum_product_inp_inp - (1/len_i)*(input_sum * input_sum)\n",
    "    # use the formula for the slope\n",
    "    slope = numerator/denominator\n",
    "    # use the formula for the intercept\n",
    "    intercept = output_mean - (slope * input_mean)\n",
    "    return (intercept, slope)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ok7ZYewUTALz"
   },
   "source": [
    "We can test that our function works by passing it something where we know the answer. In particular we can generate a feature and then put the output exactly on a line: output = 1 + 1\\*input_feature then we know both our slope and intercept should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gT43m8C7TAL0",
    "outputId": "3f101030-ea9c-4b86-c167-5d9415c8ff2c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0    1.0\n",
      "dtype: float64\n",
      "Slope: 0    1.0\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature = pd.DataFrame(range(5))\n",
    "test_output = pd.DataFrame(1 + 1*test_feature)\n",
    "(test_intercept, test_slope) =  simple_linear_regression(test_feature, test_output)\n",
    "print(\"Intercept: \" + str(test_intercept))\n",
    "print(\"Slope: \" + str(test_slope))\n",
    "test_intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3VEXlct2TAL0"
   },
   "source": [
    "Now that we know it works let's build a regression model for predicting price based on sqft_living. Rembember that we train on train_data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24VXudEYTAL0",
    "outputId": "1d0b2026-0045-42bf-af1e-e36a6b98aa49"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -47116.07907289418\n",
      "Slope: 281.9588396303426\n"
     ]
    }
   ],
   "source": [
    "sqft_intercept, sqft_slope = simple_linear_regression(train_data['sqft_living'], train_data['price'])\n",
    "\n",
    "print(\"Intercept: \" + str(sqft_intercept))\n",
    "print(\"Slope: \" + str(sqft_slope))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tElaT3yUTAL0"
   },
   "source": [
    "# Predicting values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VDBdHWHTAL1"
   },
   "source": [
    "<font color='red'> **rubric={5 points}** </font>\n",
    "\n",
    "Now that we have the model parameters: intercept & slope we can make predictions. Using DataFrame it's easy to multiply an DataFrame column by a constant and add a constant value. Complete the following function to return the predicted output given the input_feature, slope and intercept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PsrarDsvTAL1"
   },
   "outputs": [],
   "source": [
    "def get_regression_predictions(input_feature, intercept, slope):\n",
    "    # calculate the predicted values:\n",
    "    predicted_values = intercept + (slope * input_feature)\n",
    "    return predicted_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dapkG8duTAL1"
   },
   "source": [
    "Now that we can calculate a prediction given the slope and intercept let's make a prediction. Use (or alter) the following to find out the estimated price for a house with 2650 squarefeet according to the squarefeet model we estiamted above.\n",
    "\n",
    "<font color='red'> **rubric={2 points}** </font>\n",
    "\n",
    "**Quiz Question: Using your Slope and Intercept, What is the predicted price for a house with 2650 sqft?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Sa2uu_STAL1",
    "outputId": "0061f8d8-8a2a-4fcf-bf7e-f6ea3ae26d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated price for a house with 2650 squarefeet is $700074.85\n"
     ]
    }
   ],
   "source": [
    "my_house_sqft = 2650\n",
    "estimated_price = get_regression_predictions(my_house_sqft, sqft_intercept, sqft_slope)\n",
    "print(\"The estimated price for a house with %d squarefeet is $%.2f\" % (my_house_sqft, estimated_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z08XiAXKTAL1"
   },
   "source": [
    "# Residual Sum of Squares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L_pYR9zLTAL2"
   },
   "source": [
    "<font color='red'> **rubric={10 points}** </font> \n",
    "\n",
    "Now that we have a model and can make predictions let's evaluate our model using Residual Sum of Squares (RSS). Recall that RSS is the sum of the squares of the residuals and the residuals is just a fancy word for the difference between the predicted output and the true output. \n",
    "\n",
    "Complete the following (or write your own) function to compute the RSS of a simple linear regression model given the input_feature, output, intercept and slope:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NQgEUXl-TAL2"
   },
   "outputs": [],
   "source": [
    "def get_residual_sum_of_squares(input_feature, output, intercept, slope):\n",
    "    # First get the predictions\n",
    "    predictions = get_regression_predictions(input_feature,intercept, slope)\n",
    "    # then compute the residuals (since we are squaring it doesn't matter which order you subtract)\n",
    "    residuals = predictions-output\n",
    "    # square the residuals and add them up\n",
    "    residuals_squared = residuals ** 2\n",
    "    RSS = residuals_squared.sum()\n",
    "    return(RSS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWncCtAITAL2"
   },
   "source": [
    "Let's test our get_residual_sum_of_squares function by applying it to the test model where the data lie exactly on a line. Since they lie exactly on a line the residual sum of squares should be zero!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dTFuY6PNTAL2",
    "outputId": "50a3ea8b-369d-4e08-c30d-0e4dd7725f44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(get_residual_sum_of_squares(test_feature, test_output, test_intercept, test_slope)) # should be 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKxA37cDTAL2"
   },
   "source": [
    "Now use your function to calculate the RSS on training data from the squarefeet model calculated above.\n",
    "\n",
    "<font color='red'> **rubric={2 points}** </font> \n",
    "\n",
    "**Quiz Question: According to this function and the slope and intercept from the squarefeet model What is the RSS for the simple linear regression using squarefeet to predict prices on TRAINING data?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bEsJtsgvTAL2",
    "outputId": "665f24bf-c7e9-4836-a6e0-74b547ed0eed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RSS of predicting Prices based on Square Feet is : 1201918354177283.0\n",
      "The RSS of predicting Prices based on Square Feet is :  1.20192e+15\n"
     ]
    }
   ],
   "source": [
    "rss_prices_on_sqft = get_residual_sum_of_squares(train_data['sqft_living'], train_data['price'], sqft_intercept, sqft_slope)\n",
    "print('The RSS of predicting Prices based on Square Feet is : ' + str(rss_prices_on_sqft))\n",
    "print('The RSS of predicting Prices based on Square Feet is : '  ,format(rss_prices_on_sqft,'.5e'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0CU5rrLTAL3"
   },
   "source": [
    "# Predict the squarefeet given price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_r90yAPmTAL3"
   },
   "source": [
    "What if we want to predict the squarefoot given the price? Since we have an equation y = b + w\\*x we can solve the function for x. So that if we have the intercept (b) and the slope (w) and the price (y) we can solve for the estimated squarefeet (x).\n",
    "\n",
    "<font color='red'> **rubric={5 points}** </font>\n",
    "\n",
    "Complete the following function to compute the inverse regression estimate, i.e. predict the input_feature given the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ConKPsMKTAL3"
   },
   "outputs": [],
   "source": [
    "def inverse_regression_predictions(output, intercept, slope):\n",
    "    # solve output = intercept + slope*input_feature for input_feature. Use this equation to compute the inverse predictions:\n",
    "    estimated_feature = (output - intercept) / slope\n",
    "    return estimated_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3w_JQGNYTAL3"
   },
   "source": [
    "Now that we have a function to compute the squarefeet given the price from our simple regression model let's see how big we might expect a house that costs $800,000 to be.\n",
    "\n",
    "<font color='red'> **rubric={2 points}** </font>\n",
    "\n",
    "**Quiz Question: According to this function and the regression slope and intercept from (3) what is the estimated square-feet for a house costing $800,000?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "32fq7yYfTAL3",
    "outputId": "4a432c26-d4d7-4b85-ab44-f053ae341c25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated squarefeet for a house worth $800000.00 is 3004\n"
     ]
    }
   ],
   "source": [
    "my_house_price = 800000\n",
    "estimated_squarefeet = inverse_regression_predictions(my_house_price, sqft_intercept, sqft_slope)\n",
    "print(\"The estimated squarefeet for a house worth $%.2f is %d\" % (my_house_price, estimated_squarefeet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CWzbm8y-TAL4"
   },
   "source": [
    "# New Model: Estimate prices from bedrooms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E8f-UimhTAL4"
   },
   "source": [
    "<font color='red'> **rubric={2 points}** </font> \n",
    "\n",
    "We have made one model for predicting house prices using squarefeet, but there are many other features in the sales DataFrame. \n",
    "Use your simple linear regression function to estimate the regression parameters from predicting Prices based on number of bedrooms. Use the training data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fZIqFLs8TAL4",
    "outputId": "90cc911c-6597-4eb6-9778-f04bd556fb9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept for predicting price: 109473.17762295867\n",
      "Slope for predicting price: 127588.9529339881\n"
     ]
    }
   ],
   "source": [
    "# Estimate the slope and intercept for predicting 'price' based on 'bedrooms'\n",
    "bedrooms_intercept, bedrooms_slope = simple_linear_regression(train_data['bedrooms'], train_data['price'])\n",
    "\n",
    "print(\"Intercept for predicting price: \" + str(bedrooms_intercept))\n",
    "print(\"Slope for predicting price: \" + str(bedrooms_slope))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WNRT6-TyTAL4"
   },
   "source": [
    "# Test your linear regression algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NKrPFo4zTAL4"
   },
   "source": [
    "Now we have two models for predicting the price of a house. How do we know which one is better? Calculate the RSS on the TEST data (remember this data wasn't involved in learning the model). Compute the RSS from predicting prices using bedrooms and from predicting prices using squarefeet.\n",
    "\n",
    "<font color='red'> **rubric={4 points}** </font> \n",
    "\n",
    "**Quiz Question: Which model (square feet or bedrooms) has lowest RSS on TEST data? Think about why this might be the case.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pZMODWGWTAL4",
    "outputId": "eb07f9c6-6a82-4c60-bb01-812bfce82ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS for bedrooms on TEST data: 493364585960301.0\n"
     ]
    }
   ],
   "source": [
    "# Compute RSS when using bedrooms on TEST data:\n",
    "rssprices_on_bedrooms = get_residual_sum_of_squares(test_data['bedrooms'], test_data['price'], bedrooms_intercept, bedrooms_slope)\n",
    "print('RSS for bedrooms on TEST data: ' + str(rssprices_on_bedrooms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tejw3rarTAL5",
    "outputId": "c468fb3c-80aa-4f1c-dfa3-0cb3403c763d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS for squarfeet on TEST data: 275402933617812.12\n"
     ]
    }
   ],
   "source": [
    "# Compute RSS when using squarefeet on TEST data:\n",
    "rssprices_on_sqft = get_residual_sum_of_squares(test_data['sqft_living'], test_data['price'], sqft_intercept, sqft_slope)\n",
    "print('RSS for squarfeet on TEST data: ' + str(rssprices_on_sqft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBFtqZ64q6WU"
   },
   "source": [
    "# Task 2: Multivariable linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpJk4eQOq6WU"
   },
   "source": [
    "# Convert to Numpy Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J40Shpjgq6WU"
   },
   "source": [
    "Although DataFrames offer a number of benefits to users in order to understand the details of the implementation of algorithms it's important to work with a library that allows for direct (and optimized) matrix operations. Numpy is a Python solution to work with matrices (or any multi-dimensional \"array\").\n",
    "\n",
    "Recall that the predicted value given the weights and the features is just the dot product between the feature and weight vector. Similarly, if we put all of the features row-by-row in a matrix then the predicted value for *all* the observations can be computed by right multiplying the \"feature matrix\" by the \"weight vector\". \n",
    "\n",
    "First we need to take the DataFrame of our data and convert it into a 2D numpy array (also called a matrix). We can then use Panda's .to_numpy() to convert the dataframe into a numpy matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "J87f2Irxq6WU"
   },
   "outputs": [],
   "source": [
    "import numpy as np # note this allows us to refer to numpy as np instead "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "36Q3LQufq6WU"
   },
   "source": [
    "<font color='red'> **rubric = {7 points}** </font> \n",
    "\n",
    "Now we will write a function that will accept a DataFrame, a list of feature names (e.g. ['sqft_living', 'bedrooms']) and an target feature e.g. ('price') and will return two things:\n",
    "* A numpy matrix whose columns are the desired features plus a constant column (this is how we create an 'intercept')\n",
    "* A numpy array containing the values of the output\n",
    "\n",
    "With this in mind, complete the following function (where there's an empty line you should write a line of code that does what the comment above indicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "LoPUORK7q6WU"
   },
   "outputs": [],
   "source": [
    "def get_numpy_data(data_dframe, features, output):\n",
    "    data_dframe['constant'] = 1 # this is how you add a constant column to a DataFrame\n",
    "    # add the column 'constant' to the front of the features list so that we can extract it along with the others:\n",
    "    features = ['constant'] + features # this is how you combine two lists\n",
    "    # select the columns of data_dframe given by the features list into the DataFrame features_dframe (now including constant):\n",
    "    features_dframe = data_dframe[features]\n",
    "    # the following line will convert the features_dframe into a numpy matrix:\n",
    "    feature_matrix = features_dframe.to_numpy()\n",
    "    # assign the column of data_dframe associated with the output to the DataFrame column output_darray\n",
    "    output_darray = data_dframe[output]\n",
    "    # the following will convert the DataFrame column into a numpy array by first converting it to a list\n",
    "    output_array = output_darray.to_numpy()\n",
    "    return(feature_matrix, output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbTX_xdTq6WU"
   },
   "source": [
    "For testing let's use the 'sqft_living' feature and a constant as our features and price as our output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0OMEtqRTq6WV",
    "outputId": "5a5c0017-7ed1-4e01-f5dc-4bcbd8e94663"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00e+00 1.18e+03]\n",
      "221900.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') # the [] around 'sqft_living' makes it a list\n",
    "print(example_features[0,:]) # this accesses the first row of the data the ':' indicates 'all columns'\n",
    "print(example_output[0]) # and the corresponding output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vS-R9jLAq6WV"
   },
   "source": [
    "# Predicting output given regression weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uAk8XWsVq6WV"
   },
   "source": [
    "Suppose we had the weights [1.0, 1.0] and the features [1.0, 1180.0] and we wanted to compute the predicted output 1.0\\*1.0 + 1.0\\*1180.0 = 1181.0 this is the dot product between these two arrays. If they're numpy arrayws we can use np.dot() to compute this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DxzOKpchq6WV",
    "outputId": "c5e23c1f-efff-483d-f9e1-9e05e3c87cd4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181.0\n"
     ]
    }
   ],
   "source": [
    "my_weights = np.array([1., 1.]) # the example weights\n",
    "my_features = example_features[0,] # we'll use the first data point\n",
    "predicted_value = np.dot(my_features, my_weights)\n",
    "print(predicted_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQG4FFE9q6WV"
   },
   "source": [
    "<font color='red'> **rubric={5 points}** </font>\n",
    "\n",
    "np.dot() also works when dealing with a matrix and a vector. Recall that the predictions from all the observations is just the RIGHT (as in weights on the right) dot product between the features *matrix* and the weights *vector*. With this in mind finish the following predict_output function to compute the predictions for an entire matrix of features given the matrix and the weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "dWh6qhwsq6WV"
   },
   "outputs": [],
   "source": [
    "def predict_output(feature_matrix, weights):\n",
    "    # assume feature_matrix is a numpy matrix containing the features as columns and weights is a corresponding numpy array\n",
    "    # create the predictions vector by using np.dot()\n",
    "    predictions = np.dot(feature_matrix, weights)\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qgawnCrCq6WV"
   },
   "source": [
    "If you want to test your code run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tE2VRCRFq6WV",
    "outputId": "a9227143-2d45-497c-b29f-0043963934b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181.0\n",
      "2571.0\n"
     ]
    }
   ],
   "source": [
    "test_predictions = predict_output(example_features, my_weights)\n",
    "print(test_predictions[0]) # should be 1181.0\n",
    "print(test_predictions[1]) # should be 2571.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aI0eoLt8q6WV"
   },
   "source": [
    "# Computing the derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCCVpKSlq6WW"
   },
   "source": [
    "We are now going to move to computing the derivative of the regression cost function. Recall that the cost function is the sum over the data points of the squared difference between an observed output and a predicted output.\n",
    "\n",
    "Since the derivative of a sum is the sum of the derivatives we can compute the derivative for a single data point and then sum over data points. We can write the squared difference between the observed output and predicted output for a single point as follows:\n",
    "\n",
    "(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)^2\n",
    "\n",
    "Where we have k features and a constant. So the derivative with respect to weight w[i] by the chain rule is:\n",
    "\n",
    "2\\*(w[0]\\*[CONSTANT] + w[1]\\*[feature_1] + ... + w[i] \\*[feature_i] + ... +  w[k]\\*[feature_k] - output)\\* [feature_i]\n",
    "\n",
    "The term inside the paranethesis is just the error (difference between prediction and output). So we can re-write this as:\n",
    "\n",
    "2\\*error\\*[feature_i]\n",
    "\n",
    "That is, the derivative for the weight for feature i is the sum (over data points) of 2 times the product of the error and the feature itself. In the case of the constant then this is just twice the sum of the errors!\n",
    "\n",
    "Recall that twice the sum of the product of two vectors is just twice the dot product of the two vectors. Therefore the derivative for the weight for feature_i is just two times the dot product between the values of feature_i and the current errors. \n",
    "\n",
    "<font color='red'> **rubric={5 points}** </font>\n",
    "\n",
    " With this in mind complete the following derivative function which computes the derivative of the weight given the value of the feature (over all data points) and the errors (over all data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "d0wxLEOFq6WW"
   },
   "outputs": [],
   "source": [
    "def feature_derivative(errors, feature):\n",
    "    # Assume that errors and feature are both numpy arrays of the same length (number of data points)\n",
    "    # compute twice the dot product of these vectors as 'derivative' and return the value\n",
    "    derivative = np.dot(errors,feature) * 2\n",
    "\n",
    "    return(derivative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NRu-BhRJq6WW"
   },
   "source": [
    "To test your feature derivartive run the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "580n_hA0q6WW",
    "outputId": "ffb0b3ba-c38c-449c-a457-60ab0042cfb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-23345850016.0\n",
      "-23345850016.0\n"
     ]
    }
   ],
   "source": [
    "(example_features, example_output) = get_numpy_data(sales, ['sqft_living'], 'price') \n",
    "my_weights = np.array([0., 0.]) # this makes all the predictions 0\n",
    "test_predictions = predict_output(example_features, my_weights) \n",
    "# just like DataFrames 2 numpy arrays can be elementwise subtracted with '-': \n",
    "errors = test_predictions - example_output # prediction errors in this case is just the -example_output\n",
    "feature = example_features[:,0] # let's compute the derivative with respect to 'constant', the \":\" indicates \"all rows\"\n",
    "derivative = feature_derivative(errors, feature)\n",
    "print(derivative)\n",
    "print(-np.sum(example_output)*2) # should be the same as derivative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QiwVHjTVq6WW"
   },
   "source": [
    "# Gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JFzWAdHKq6WW"
   },
   "source": [
    "Now we will write a function that performs a gradient descent. The basic premise is simple. Given a starting point we update the current weights by moving in the negative gradient direction. Recall that the gradient is the direction of *increase* and therefore the negative gradient is the direction of *decrease* and we're trying to *minimize* a cost function. \n",
    "\n",
    "The amount by which we move in the negative gradient *direction*  is called the 'step size'. We stop when we are 'sufficiently close' to the optimum. We define this by requiring that the magnitude (length) of the gradient vector to be smaller than a fixed 'tolerance'.\n",
    "\n",
    "<font color='red'> **rubric={20 points}** \n",
    "\n",
    "</font>With this in mind, complete the following gradient descent function below using your derivative function above. For each step in the gradient descent we update the weight for each feature befofe computing our stopping criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "gT5Xk_o9q6WW"
   },
   "outputs": [],
   "source": [
    "from math import sqrt # recall that the magnitude/length of a vector [g[0], g[1], g[2]] is sqrt(g[0]^2 + g[1]^2 + g[2]^2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "v6u9sMNQq6WW"
   },
   "outputs": [],
   "source": [
    "def regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance):\n",
    "    converged = False \n",
    "    weights = np.array(initial_weights) # make sure it's a numpy array\n",
    "    while not converged:\n",
    "        # compute the predictions based on feature_matrix and weights using your predict_output() function\n",
    "        predictions = predict_output(feature_matrix, weights)\n",
    "\n",
    "        # compute the errors as predictions - output\n",
    "        errors = predictions - output\n",
    "        gradient_sum_squares = 0 # initialize the gradient sum of squares\n",
    "        # while we haven't reached the tolerance yet, update each feature's weight\n",
    "        for i in range(len(weights)): # loop over each weight\n",
    "            # Recall that feature_matrix[:, i] is the feature column associated with weights[i]\n",
    "            # compute the derivative for weight[i]:\n",
    "            derivative = feature_derivative(errors, feature_matrix[:, i])\n",
    "            # add the squared value of the derivative to the gradient sum of squares (for assessing convergence)\n",
    "            gradient_sum_squares += np.power(derivative, 2)\n",
    "            # subtract the step size times the derivative from the current weight\n",
    "            weights[i] -= step_size * derivative\n",
    "\n",
    "        # compute the square-root of the gradient sum of squares to get the gradient magnitude:\n",
    "        gradient_magnitude = sqrt(gradient_sum_squares)\n",
    "        if gradient_magnitude < tolerance:\n",
    "            converged = True\n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbUDCy_Jq6WW"
   },
   "source": [
    "A few things to note before we run the gradient descent. Since the gradient is a sum over all the data points and involves a product of an error and a feature the gradient itself will be very large since the features are large (squarefeet) and the output is large (prices). So while you might expect \"tolerance\" to be small, small is only relative to the size of the features. \n",
    "\n",
    "For similar reasons the step size will be much smaller than you might expect but this is because the gradient has such large values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wM7UDEDvq6WW"
   },
   "source": [
    "# Running the gradient descent as simple regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SWU4buxrq6WX"
   },
   "source": [
    "Although the gradient descent is designed for multivariable regression since the constant is now a feature we can use the gradient descent function to estimate the parameters in the simple regression on squarefeet. The folowing cell sets up the feature_matrix, output, initial weights and step size for the first model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "DgYI5yJ9q6WX"
   },
   "outputs": [],
   "source": [
    "# let's test out the gradient descent\n",
    "simple_features = ['sqft_living']\n",
    "my_output = 'price'\n",
    "(simple_feature_matrix, output) = get_numpy_data(train_data, simple_features, my_output)\n",
    "initial_weights = np.array([-47000., 1.])\n",
    "step_size = 7e-12\n",
    "tolerance = 2.5e7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i7QWZi21q6WX"
   },
   "source": [
    "<font color='red'> **{2 points}** </font>Next run your gradient descent with the above parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LUo3DpOIq6WX",
    "outputId": "9056e538-6852-4d90-a5d0-09a54cc58837"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-46999.88716555    281.91211918]\n"
     ]
    }
   ],
   "source": [
    "weights = regression_gradient_descent(simple_feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kRV57ccoq6WX"
   },
   "source": [
    "How do your weights compare to those achieved in week 1 (don't expect them to be exactly the same)? \n",
    "\n",
    "**Quiz Question: What is the value of the weight for sqft_living -- the second element of ‘simple_weights’ (rounded to 1 decimal place)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "281.9"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(weights[1],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXMF6_fRq6WX"
   },
   "source": [
    "<font color='red'> **{2 points}** </font>Use your newly estimated weights and your predict_output() function to compute the predictions on all the TEST data (you will need to create a numpy array of the test feature_matrix and test output first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "pkGTDLRJq6WX"
   },
   "outputs": [],
   "source": [
    "(test_simple_feature_matrix, test_output) = get_numpy_data(test_data, simple_features, my_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_50G5-9Bq6WX"
   },
   "source": [
    "<font color='red'> **{2 points}** </font>Now compute your predictions using test_simple_feature_matrix and your weights from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DBT_om9zq6WX"
   },
   "outputs": [],
   "source": [
    "test_simple_predictions = predict_output(test_simple_feature_matrix,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mqy-7wcvq6WX"
   },
   "source": [
    "<font color='red'> **{1 point}** </font>**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 1 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hd5Rj1sYq6WX",
    "outputId": "4104df57-7219-4aa6-9003-e1f8f2493f93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[356134.]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(test_simple_predictions[0:1],0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wJY82wfq6WX"
   },
   "source": [
    "<font color='red'> **{2 points}** </font>Now that you have the predictions on test data, compute the RSS on the test data set. Save this value for comparison later. Recall that RSS is the sum of the squared errors (difference between prediction and output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bnV59Q4q6WX",
    "outputId": "918251b2-a4f5-407e-af34-6c85091d96a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275400044902128.78\n"
     ]
    }
   ],
   "source": [
    "test_simple_residuals = test_simple_predictions - test_data['price']\n",
    "test_simple_rss = sum(test_simple_residuals * test_simple_residuals)\n",
    "print(test_simple_rss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GujuA1hdq6WY"
   },
   "source": [
    "# Running a multivariable regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MipMk8jYq6WY"
   },
   "source": [
    "Now we will use more than one actual feature. Use the following code to produce the weights for a second model with the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "fLDddbxUq6WY"
   },
   "outputs": [],
   "source": [
    "model_features = ['sqft_living', 'sqft_living15'] # sqft_living15 is the average squarefeet for the nearest 15 neighbors. \n",
    "my_output = 'price'\n",
    "(feature_matrix, output) = get_numpy_data(train_data, model_features, my_output)\n",
    "initial_weights = np.array([-100000., 1., 1.])\n",
    "step_size = 4e-12\n",
    "tolerance = 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpVZcwn1q6WY"
   },
   "source": [
    "<font color='red'> **{2 points}** </font>Use the above parameters to estimate the model weights. Record these values for the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n5iB7UlGq6WY",
    "outputId": "5a01c2f9-7db3-4cb4-d49b-186f8b59bfbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.99999688e+04  2.45072603e+02  6.52795267e+01]\n"
     ]
    }
   ],
   "source": [
    "multi_weights = regression_gradient_descent(feature_matrix, output, initial_weights, step_size, tolerance)\n",
    "print(multi_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q3SNY67Uq6WY"
   },
   "source": [
    "<font color='red'> **{2 points}** </font>Use your newly estimated weights and the predict_output function to compute the predictions on the TEST data. Don't forget to create a numpy array for these features from the test set first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "UO9GNqhtq6WY"
   },
   "outputs": [],
   "source": [
    "(multi_feature_matrix, multi_output) = get_numpy_data(test_data, model_features, my_output)\n",
    "multi_predictions = predict_output(multi_feature_matrix, multi_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8btRmhV9q6WY"
   },
   "source": [
    "<font color='red'> **{1 point}** </font>**Quiz Question: What is the predicted price for the 1st house in the TEST data set for model 2 (round to nearest dollar)?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zBHhe2Qjq6WY",
    "outputId": "d15c1c2e-13c0-45eb-a7f8-999f3dda9139"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[366651.]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(multi_predictions[0:1],0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFdhl8m-q6WY"
   },
   "source": [
    "<font color='red'> **{1 point}** </font>What is the actual price for the 1st house in the test data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2GHxojXsq6WY",
    "outputId": "953cb7a8-fcd7-48c0-9480-4e6c11811474"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "310000.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['price'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h7N6RD6uq6WY"
   },
   "source": [
    "<font color='red'> **{1 points}** </font> **Quiz Question: Which estimate was closer to the true price for the 1st house on the TEST data set, model 1 or model 2?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "qOugIsakFq6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1 was closer\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL 1 was closer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBmkOIO8q6WY"
   },
   "source": [
    "<font color='red'> **{2 points}** </font>Now use your predictions and the output to compute the RSS for model 2 on TEST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gE7854Fqq6WY",
    "outputId": "c11279b4-92ca-49ca-baca-19fe13d356d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270263443629803.3\n"
     ]
    }
   ],
   "source": [
    "multi_residuals = multi_predictions - test_data['price']\n",
    "multi_rss = sum(multi_residuals * multi_residuals)\n",
    "print(multi_rss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vA9hMR_Fq6WY"
   },
   "source": [
    "<font color='red'> **{1 points}** </font> Which model (1 or 2) has lowest RSS on all of the TEST data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CignaBO4q6WY",
    "outputId": "b0c5c27c-2b80-428b-acc5-d1449847240a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL2 has lowest RSS on all of the TEST data\n"
     ]
    }
   ],
   "source": [
    "print(\"MODEL2 has lowest RSS on all of the TEST data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9yMIloSlFq6b"
   },
   "source": [
    "## Submission instructions \n",
    "\n",
    "**PLEASE READ:** When you are ready to submit your assignment do the following:\n",
    "\n",
    "1. Run all cells in your notebook to make sure there are no errors by doing `Kernel -> Restart Kernel and Clear All Outputs` and then `Run -> Run All Cells`.\n",
    "2. Notebooks with cell execution numbers out of order will have marks deducted. Notebooks without the output displayed may not be graded at all (because we need to see the output in order to grade your work).\n",
    "3. Please keep your notebook clean and remove any throwaway code."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
